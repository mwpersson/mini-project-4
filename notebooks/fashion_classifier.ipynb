{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 9130 - Mini Project 4: Deep Learning Classifier\n",
    "## Fashion-MNIST Classification for StyleSort\n",
    "\n",
    "**Framework:** PyTorch  \n",
    "**Dataset:** Fashion-MNIST (60,000 train / 10,000 test, 28\u00d728 grayscale, 10 classes)  \n",
    "**Goal:** Build a product image classification system achieving >85% accuracy with business-aware error analysis.\n",
    "\n",
    "### Business Context\n",
    "\n",
    "StyleSort is an online fashion retailer processing over 100,000 product listings per month. ",
    "Their current return rate is **32%**, significantly higher than the industry average of 20%. ",
    "Customer surveys reveal that **40% of returns** happen because \"the item wasn't what I expected\" \u2014 ",
    "often due to products being miscategorized in the catalog. Examples include formal Shirts listed as ",
    "casual T-shirts, Ankle boots categorized as Sandals, and Coats listed as Pullovers.\n",
    "\n",
    "### Our Approach\n",
    "\n",
    "We train and compare **5 different neural network configurations** using PyTorch `nn.Module`, ",
    "varying architecture depth, activation functions, hidden layer sizes, and batch normalization. ",
    "We then perform business-oriented analysis including confusion matrix analysis, cost-weighted ",
    "accuracy, confidence threshold analysis, and misclassification visualization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Class labels for FashionMNIST\n",
    "class_names = train_data.classes\n",
    "\n",
    "# Dataset statistics\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(f\"Class names: {class_names}\") \n",
    "print(f\"Image shape: {train_data[0][0].shape}\")\n",
    "\n",
    "# Class distribution\n",
    "train_labels = [label for _, label in train_data]\n",
    "unique, counts = np.unique(train_labels, return_counts=True)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar([class_names[i] for i in unique], counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Training Data Class Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display sample images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image, label = train_data[i]\n",
    "    ax.imshow(image.squeeze(), cmap='gray')\n",
    "    ax.set_title(class_names[label])\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Model Definition\n",
    "\n",
    "We flatten the 28\u00d728 images into 784-dimensional vectors and normalize pixel values to [0, 1]. ",
    "A 90/10 train/validation split is used to monitor overfitting during training."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():  # For Apple Silicon GPUs\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Flatten images and normalize to [0, 1]\n",
    "x_train_flattened = torch.flatten(train_data.data, start_dim=1).float() / 255.0\n",
    "y_train = train_data.targets\n",
    "\n",
    "x_test_flattened = torch.flatten(test_data.data, start_dim=1).float() / 255.0\n",
    "y_test = test_data.targets\n",
    "\n",
    "train_data_flattened = torch.utils.data.TensorDataset(x_train_flattened, y_train)\n",
    "test_data_flattened = torch.utils.data.TensorDataset(x_test_flattened, y_test)\n",
    "\n",
    "loss_histories = []\n",
    "accuracy_histories = []\n",
    "\n",
    "print(f\"Flattened training data shape: {x_train_flattened.shape}\")\n",
    "print(f\"Flattened test data shape: {x_test_flattened.shape}\")\n",
    "\n",
    "test_loader = DataLoader(test_data_flattened, batch_size=64, shuffle=False)\n",
    "\n",
    "# Create validation set (10% of training data)\n",
    "val_size = int(0.1 * len(train_data_flattened))\n",
    "train_size = len(train_data_flattened) - val_size\n",
    "train_data_split, val_data = torch.utils.data.random_split(train_data_flattened, [train_size, val_size])\n",
    "train_loader = DataLoader(train_data_split, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition (`nn.Module`)\n",
    "\n",
    "We define a flexible `FashionClassifier` class using `nn.Module` that supports:\n",
    "- Configurable number of hidden layers (1, 2, or 3)\n",
    "- Configurable hidden layer size\n",
    "- Configurable activation function (ReLU, LeakyReLU, ELU)\n",
    "- Optional batch normalization\n",
    "- Optional dropout\n",
    "\n",
    "This allows us to systematically compare different architectures."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class FashionClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Flexible MLP classifier for Fashion-MNIST.\n",
    "    Supports configurable depth, width, activation, batch norm, and dropout.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=784, num_classes=10, hidden_layers=2,\n",
    "                 activation_fn=nn.ReLU(), hidden_size=256,\n",
    "                 batch_norm=False, dropout_prob=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        in_features = input_size\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            out_features = hidden_size\n",
    "            layers.append(nn.Linear(in_features, out_features))\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(out_features))\n",
    "            layers.append(activation_fn)\n",
    "            if dropout_prob > 0:\n",
    "                layers.append(nn.Dropout(dropout_prob))\n",
    "            in_features = out_features\n",
    "\n",
    "        layers.append(nn.Linear(in_features, num_classes))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "# Quick test\n",
    "test_model = FashionClassifier()\n",
    "test_input = torch.randn(2, 784)\n",
    "test_output = test_model(test_input)\n",
    "print(f\"Model output shape: {test_output.shape}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in test_model.parameters()):,}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Training Loop\n",
    "\n",
    "We implement a manual training loop that:\n",
    "1. Performs forward pass, computes cross-entropy loss, backward pass, and weight updates\n",
    "2. Tracks training loss and validation accuracy per epoch\n",
    "3. Returns loss and accuracy histories for plotting"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5, device='cpu'):\n",
    "    \"\"\"\n",
    "    Train the model and track loss/accuracy per epoch.\n",
    "    \n",
    "    Returns:\n",
    "        loss_history: list of training losses per epoch\n",
    "        accuracy_history: list of validation accuracies per epoch\n",
    "    \"\"\"\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and weight update\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        avg_loss = running_loss / num_batches\n",
    "        loss_history.append(avg_loss)\n",
    "\n",
    "        # Validation accuracy\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100.0 * correct / total\n",
    "        accuracy_history.append(accuracy)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}] - Loss: {loss_history[-1]:.4f} - Val Acc: {accuracy:.2f}%')\n",
    "\n",
    "    return loss_history, accuracy_history\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cpu'):\n",
    "    \"\"\"Evaluate model on test set and return accuracy.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training 5 Model Configurations\n",
    "\n",
    "We compare 5 different configurations to find the best architecture:\n",
    "\n",
    "| Classifier | Layers | Activation | Hidden Size | Batch Norm | Dropout | Optimizer |\n",
    "|-----------|--------|-----------|-------------|-----------|---------|----------|\n",
    "| 1 (Best) | 3 | ELU | 512 | Yes | 0.0 | Adam |\n",
    "| 2 | 3 | ReLU | 256 | No | 0.0 | Adam |\n",
    "| 3 | 2 | ReLU | 256 | No | 0.0 | Adam |\n",
    "| 4 | 3 | ReLU | 128 | Yes | 0.0 | Adam |\n",
    "| 5 | 2 | ELU | 256 | Yes | 0.0 | AdamW |\n",
    "\n",
    "These configurations were selected based on a prior hyperparameter grid search ",
    "over hidden layers, activation functions, hidden sizes, optimizers, batch normalization, ",
    "and dropout rates."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "classifiers = []\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# ---- Classifier 1: 3 layers, ELU, 512, BN, Adam ----\n",
    "print('=' * 60)\n",
    "print('Classifier 1: 3 layers, ELU, hidden=512, BN=True, Adam')\n",
    "print('=' * 60)\n",
    "classifier1 = FashionClassifier(\n",
    "    hidden_layers=3, activation_fn=nn.ELU(), hidden_size=512,\n",
    "    batch_norm=True, dropout_prob=0.0\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier1.parameters(), lr=0.001)\n",
    "classifier1 = classifier1.to(device)\n",
    "classifier1_loss_history, classifier1_accuracy_history = train_model(\n",
    "    classifier1, train_loader, val_loader, criterion, optimizer, epochs=NUM_EPOCHS, device=device\n",
    ")\n",
    "classifier1_accuracy = evaluate_model(classifier1, test_loader, device=device)\n",
    "loss_histories.append(classifier1_loss_history)\n",
    "accuracy_histories.append(classifier1_accuracy_history)\n",
    "classifiers.append(classifier1)\n",
    "print()\n",
    "\n",
    "# ---- Classifier 2: 3 layers, ReLU, 256, no BN, Adam ----\n",
    "print('=' * 60)\n",
    "print('Classifier 2: 3 layers, ReLU, hidden=256, BN=False, Adam')\n",
    "print('=' * 60)\n",
    "classifier2 = FashionClassifier(\n",
    "    hidden_layers=3, activation_fn=nn.ReLU(), hidden_size=256,\n",
    "    batch_norm=False, dropout_prob=0.0\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier2.parameters(), lr=0.001)\n",
    "classifier2 = classifier2.to(device)\n",
    "classifier2_loss_history, classifier2_accuracy_history = train_model(\n",
    "    classifier2, train_loader, val_loader, criterion, optimizer, epochs=NUM_EPOCHS, device=device\n",
    ")\n",
    "classifier2_accuracy = evaluate_model(classifier2, test_loader, device=device)\n",
    "loss_histories.append(classifier2_loss_history)\n",
    "accuracy_histories.append(classifier2_accuracy_history)\n",
    "classifiers.append(classifier2)\n",
    "print()\n",
    "\n",
    "# ---- Classifier 3: 2 layers, ReLU, 256, no BN, Adam ----\n",
    "print('=' * 60)\n",
    "print('Classifier 3: 2 layers, ReLU, hidden=256, BN=False, Adam')\n",
    "print('=' * 60)\n",
    "classifier3 = FashionClassifier(\n",
    "    hidden_layers=2, activation_fn=nn.ReLU(), hidden_size=256,\n",
    "    batch_norm=False, dropout_prob=0.0\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier3.parameters(), lr=0.001)\n",
    "classifier3 = classifier3.to(device)\n",
    "classifier3_loss_history, classifier3_accuracy_history = train_model(\n",
    "    classifier3, train_loader, val_loader, criterion, optimizer, epochs=NUM_EPOCHS, device=device\n",
    ")\n",
    "classifier3_accuracy = evaluate_model(classifier3, test_loader, device=device)\n",
    "loss_histories.append(classifier3_loss_history)\n",
    "accuracy_histories.append(classifier3_accuracy_history)\n",
    "classifiers.append(classifier3)\n",
    "print()\n",
    "\n",
    "# ---- Classifier 4: 3 layers, ReLU, 128, BN, Adam ----\n",
    "print('=' * 60)\n",
    "print('Classifier 4: 3 layers, ReLU, hidden=128, BN=True, Adam')\n",
    "print('=' * 60)\n",
    "classifier4 = FashionClassifier(\n",
    "    hidden_layers=3, activation_fn=nn.ReLU(), hidden_size=128,\n",
    "    batch_norm=True, dropout_prob=0.0\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier4.parameters(), lr=0.001)\n",
    "classifier4 = classifier4.to(device)\n",
    "classifier4_loss_history, classifier4_accuracy_history = train_model(\n",
    "    classifier4, train_loader, val_loader, criterion, optimizer, epochs=NUM_EPOCHS, device=device\n",
    ")\n",
    "classifier4_accuracy = evaluate_model(classifier4, test_loader, device=device)\n",
    "loss_histories.append(classifier4_loss_history)\n",
    "accuracy_histories.append(classifier4_accuracy_history)\n",
    "classifiers.append(classifier4)\n",
    "print()\n",
    "\n",
    "# ---- Classifier 5: 2 layers, ELU, 256, BN, AdamW ----\n",
    "print('=' * 60)\n",
    "print('Classifier 5: 2 layers, ELU, hidden=256, BN=True, AdamW')\n",
    "print('=' * 60)\n",
    "classifier5 = FashionClassifier(\n",
    "    hidden_layers=2, activation_fn=nn.ELU(), hidden_size=256,\n",
    "    batch_norm=True, dropout_prob=0.0\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(classifier5.parameters(), lr=0.001)\n",
    "classifier5 = classifier5.to(device)\n",
    "classifier5_loss_history, classifier5_accuracy_history = train_model(\n",
    "    classifier5, train_loader, val_loader, criterion, optimizer, epochs=NUM_EPOCHS, device=device\n",
    ")\n",
    "classifier5_accuracy = evaluate_model(classifier5, test_loader, device=device)\n",
    "loss_histories.append(classifier5_loss_history)\n",
    "accuracy_histories.append(classifier5_accuracy_history)\n",
    "classifiers.append(classifier5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Curves\n",
    "\n",
    "We plot the training loss and validation accuracy across epochs for all 5 classifiers ",
    "to compare convergence speed and final performance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "# Plot loss histories\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for i, loss_history in enumerate(loss_histories):\n",
    "    plt.plot(range(1, len(loss_history) + 1), loss_history, marker='o', label=f'Classifier {i+1}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot accuracy histories\n",
    "plt.subplot(1, 2, 2)\n",
    "for i, accuracy_history in enumerate(accuracy_histories):\n",
    "    plt.plot(range(1, len(accuracy_history) + 1), accuracy_history, marker='o', label=f'Classifier {i+1}')\n",
    "plt.axhline(y=85, color='r', linestyle='--', alpha=0.5, label='85% Target')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: results/training_curves.png')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Print experiment summary table\n",
    "print('\\n' + '=' * 65)\n",
    "print(f'{\"Classifier\":<15} {\"Test Accuracy\":>15} {\"Final Train Loss\":>18}')\n",
    "print('=' * 65)\n",
    "test_accs = []\n",
    "for i, clf in enumerate(classifiers):\n",
    "    clf.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = clf(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = 100.0 * correct / total\n",
    "    test_accs.append(acc)\n",
    "    final_loss = loss_histories[i][-1]\n",
    "    print(f'Classifier {i+1:<4} {acc:>14.2f}% {final_loss:>18.4f}')\n",
    "print('=' * 65)\n",
    "\n",
    "best_idx = np.argmax(test_accs)\n",
    "print(f'\\nBest model: Classifier {best_idx+1} with {test_accs[best_idx]:.2f}% test accuracy')\n",
    "print(f'Target >85%: {\"PASSED \u2713\" if test_accs[best_idx] > 85 else \"NOT MET \u2717\"}')\n",
    "best_classifier = classifiers[best_idx]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Confusion Matrix Analysis\n",
    "\n",
    "The confusion matrix reveals which product categories are most frequently confused by the model. ",
    "This is critical for StyleSort to understand where misclassification errors occur and to ",
    "prioritize improvements in product descriptions and photography guidelines."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "for i, classifier in enumerate(classifiers):\n",
    "    # Get predictions on test set\n",
    "    classifier.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = classifier(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix for Classifier {i+1}')\n",
    "    plt.tight_layout()\n",
    "    if i == best_idx:\n",
    "        plt.savefig('results/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "        print(f'Saved confusion matrix for best model (Classifier {i+1}): results/confusion_matrix.png')\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Analyze most confused category pairs for the best classifier\n",
    "best_classifier.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = best_classifier(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "cm_best = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print('Most Confused Category Pairs (Best Model):')\n",
    "print('=' * 55)\n",
    "\n",
    "# Get off-diagonal elements\n",
    "cm_no_diag = cm_best.copy()\n",
    "np.fill_diagonal(cm_no_diag, 0)\n",
    "\n",
    "# Find top 5 confused pairs\n",
    "for _ in range(5):\n",
    "    idx = np.unravel_index(cm_no_diag.argmax(), cm_no_diag.shape)\n",
    "    count = cm_no_diag[idx]\n",
    "    true_name = class_names[idx[0]]\n",
    "    pred_name = class_names[idx[1]]\n",
    "    print(f'  {true_name:>12} -> {pred_name:<12}: {count:>4} misclassifications')\n",
    "    cm_no_diag[idx] = 0\n",
    "\n",
    "print()\n",
    "print('Key Insight: Shirt <-> T-shirt/top and Coat <-> Pullover are the most')\n",
    "print('confused pairs. This aligns with the StyleSort business context \u2014 these')\n",
    "print('categories have similar visual features in 28x28 grayscale but very')\n",
    "print('different customer expectations (formal vs casual, heavy vs light).')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Class Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Per-class precision, recall, F1 for the best model\n",
    "print('Per-Class Performance Metrics (Best Model):')\n",
    "print('=' * 65)\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
    "print(report)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Error Cost Analysis\n",
    "\n",
    "Not all misclassifications are equally costly for StyleSort. We define a cost matrix ",
    "based on business impact:\n",
    "\n",
    "| Error Type | Business Impact | Cost Level |\n",
    "|-----------|----------------|------------|\n",
    "| Bag \u2192 Sneaker | Obvious to customer, quick return | Low (1) |\n",
    "| Shirt \u2192 T-shirt | Customer expects different style | High (3) |\n",
    "| Coat \u2192 Pullover | Customer expects warmth, different size | High (3) |\n",
    "| Sandal \u2192 Sneaker | Wrong season, wrong use case | Medium (2) |\n",
    "| Ankle boot \u2192 Sneaker | Similar use, price difference | Medium (2) |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a cost matrix that penalizes certain misclassifications more heavily\n",
    "cost_matrix = np.array([\n",
    "    [0,             1,          1,          1,      1,      1,      3,      1,          1,      1],      # T-shirt/top\n",
    "    [1,             0,          1,          1,      1,      1,      1,      1,          1,      1],      # Trouser\n",
    "    [1,             1,          0,          1,      3,      1,      1,      1,          1,      1],      # Pullover\n",
    "    [1,             1,          1,          0,      1,      1,      1,      1,          1,      1],      # Dress\n",
    "    [1,             1,          3,          1,      0,      1,      1,      1,          1,      1],      # Coat\n",
    "    [1,             1,          1,          1,      1,      0,      1,      2,          1,      1],      # Sandal\n",
    "    [3,             1,          1,          1,      1,      1,      0,      1,          1,      1],      # Shirt\n",
    "    [1,             1,          1,          1,      1,      2,      1,      0,          0.5,    2],      # Sneaker\n",
    "    [1,             1,          1,          1,      1,      1,      1,      0.5,        0,      1],      # Bag\n",
    "    [1,             1,          1,          1,      1,      1,      1,      2,          1,      0],      # Ankle boot\n",
    "    #t-shirt/top,   trouser,    pullover,   dress,  coat,   sandal, shirt,  sneaker,    bag,    ankle boot\n",
    "])\n",
    "\n",
    "# Visualize cost matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cost_matrix, annot=True, fmt='.1f', cmap='YlOrRd',\n",
    "    xticklabels=class_names, yticklabels=class_names,\n",
    "    ax=ax, linewidths=0.5\n",
    ")\n",
    "ax.set_xlabel('Predicted Label', fontsize=13)\n",
    "ax.set_ylabel('True Label', fontsize=13)\n",
    "ax.set_title('StyleSort Error Cost Matrix', fontsize=15)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate standard and cost-weighted accuracy for each classifier\n",
    "for i, classifier in enumerate(classifiers):\n",
    "    classifier.eval()\n",
    "    c_preds = []\n",
    "    c_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = classifier(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c_preds.extend(predicted.cpu().numpy())\n",
    "            c_labels.extend(labels.numpy())\n",
    "\n",
    "    c_preds = np.array(c_preds)\n",
    "    c_labels = np.array(c_labels)\n",
    "    \n",
    "    # Standard accuracy\n",
    "    standard_accuracy = np.mean(c_preds == c_labels) * 100\n",
    "    \n",
    "    # Cost-weighted accuracy: penalize incorrect predictions based on cost matrix\n",
    "    total_cost = 0\n",
    "    for true_label, pred_label in zip(c_labels, c_preds):\n",
    "        total_cost += cost_matrix[true_label, pred_label]\n",
    "    \n",
    "    cost_weighted_accuracy = (1 - (total_cost / (len(c_labels) * np.max(cost_matrix)))) * 100\n",
    "    \n",
    "    print(f\"Classifier {i+1}:\")\n",
    "    print(f\"  Standard Accuracy: {standard_accuracy:.2f}%\")\n",
    "    print(f\"  Cost-Weighted Accuracy: {cost_weighted_accuracy:.2f}%\")\n",
    "    print(f\"  Total Cost: {total_cost}\")\n",
    "    print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confidence Threshold Analysis\n",
    "\n",
    "StyleSort needs to flag low-confidence predictions for human review before publishing. ",
    "We analyze how different confidence thresholds affect:\n",
    "- **Accuracy** on accepted (confident) predictions\n",
    "- **Percentage** of items that would need human review\n",
    "\n",
    "The optimal threshold balances high accuracy with minimal human review workload. ",
    "For StyleSort's 10,000 daily new listings, this determines how many items require manual review."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get softmax probabilities from the best classifier\n",
    "best_classifier.eval()\n",
    "all_preds_conf = []\n",
    "all_labels_conf = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = best_classifier(images)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds_conf.extend(predicted.cpu().numpy())\n",
    "        all_labels_conf.extend(labels.numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "all_preds_conf = np.array(all_preds_conf)\n",
    "all_labels_conf = np.array(all_labels_conf)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# Confidence threshold analysis\n",
    "max_probs = np.max(all_probs, axis=1)\n",
    "thresholds = np.arange(0.50, 1.00, 0.01)\n",
    "accuracies_at_t = []\n",
    "pct_accepted_at_t = []\n",
    "pct_review_at_t = []\n",
    "\n",
    "for t in thresholds:\n",
    "    mask = max_probs >= t\n",
    "    if mask.sum() == 0:\n",
    "        accuracies_at_t.append(0.0)\n",
    "        pct_accepted_at_t.append(0.0)\n",
    "        pct_review_at_t.append(100.0)\n",
    "    else:\n",
    "        acc = (all_preds_conf[mask] == all_labels_conf[mask]).mean() * 100\n",
    "        pct = mask.mean() * 100\n",
    "        accuracies_at_t.append(acc)\n",
    "        pct_accepted_at_t.append(pct)\n",
    "        pct_review_at_t.append(100.0 - pct)\n",
    "\n",
    "# Plot confidence threshold analysis\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color1 = 'tab:blue'\n",
    "ax1.set_xlabel('Confidence Threshold', fontsize=12)\n",
    "ax1.set_ylabel('Accuracy on Accepted (%)', color=color1, fontsize=12)\n",
    "ax1.plot(thresholds, accuracies_at_t, color=color1, linewidth=2, label='Accuracy')\n",
    "ax1.tick_params(axis='y', labelcolor=color1)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color2 = 'tab:orange'\n",
    "ax2.set_ylabel('Items Accepted (%)', color=color2, fontsize=12)\n",
    "ax2.plot(thresholds, pct_accepted_at_t, color=color2, linewidth=2, label='% Accepted')\n",
    "ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "# Mark the 80% confidence threshold\n",
    "ax1.axvline(x=0.80, color='gray', linestyle=':', alpha=0.6, label='80% threshold')\n",
    "\n",
    "fig.suptitle('Confidence Threshold Analysis for StyleSort', fontsize=14)\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.5, 0.92), ncol=3, fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "plt.savefig('results/confidence_threshold.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: results/confidence_threshold.png')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Print specific threshold analysis\n",
    "print('Confidence Threshold Analysis Summary:')\n",
    "print('=' * 65)\n",
    "print(f'{\"Threshold\":>10} {\"Accuracy\":>12} {\"Accepted\":>12} {\"Need Review\":>12}')\n",
    "print('-' * 65)\n",
    "for t_val in [0.50, 0.60, 0.70, 0.80, 0.85, 0.90, 0.95, 0.99]:\n",
    "    idx = int(round((t_val - 0.50) / 0.01))\n",
    "    if idx < len(thresholds):\n",
    "        print(f'{t_val:>10.2f} {accuracies_at_t[idx]:>11.2f}% '\n",
    "              f'{pct_accepted_at_t[idx]:>11.2f}% {pct_review_at_t[idx]:>11.2f}%')\n",
    "print('=' * 65)\n",
    "\n",
    "# Specific analysis for 80% threshold\n",
    "t80_idx = int(round((0.80 - 0.50) / 0.01))\n",
    "print(f'\\nAt 80% confidence threshold:')\n",
    "print(f'  - {pct_review_at_t[t80_idx]:.1f}% of items would need human review')\n",
    "print(f'  - Accuracy on accepted items: {accuracies_at_t[t80_idx]:.2f}%')\n",
    "print(f'  - For 10,000 daily listings: ~{int(10000 * pct_review_at_t[t80_idx] / 100)} items need review')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Misclassified Examples\n",
    "\n",
    "Visualizing misclassified images helps understand where the model struggles ",
    "and can inform improvements to StyleSort's product photography guidelines."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize 10 misclassified images with confidence scores\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Get misclassified images from the best classifier\n",
    "best_classifier.eval()\n",
    "misclassified_images = []\n",
    "misclassified_true_labels = []\n",
    "misclassified_pred_labels = []\n",
    "misclassified_confidences = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = best_classifier(images)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        max_conf, predicted = torch.max(probs, 1)\n",
    "        \n",
    "        # Find misclassified samples\n",
    "        mask = predicted != labels\n",
    "        if mask.sum() > 0:\n",
    "            misclassified_images.extend(images[mask].cpu())\n",
    "            misclassified_true_labels.extend(labels[mask].cpu().numpy())\n",
    "            misclassified_pred_labels.extend(predicted[mask].cpu().numpy())\n",
    "            misclassified_confidences.extend(max_conf[mask].cpu().numpy())\n",
    "        \n",
    "        # Stop once we have at least 10 misclassified samples\n",
    "        if len(misclassified_images) >= 10:\n",
    "            break\n",
    "\n",
    "# Plot the first 10 misclassified images\n",
    "for i in range(10):\n",
    "    # Reshape back to 28x28 for visualization\n",
    "    img = misclassified_images[i].view(28, 28)\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    conf = misclassified_confidences[i] * 100\n",
    "    axes[i].set_title(\n",
    "        f'True: {class_names[misclassified_true_labels[i]]}\\n'\n",
    "        f'Pred: {class_names[misclassified_pred_labels[i]]}\\n'\n",
    "        f'Conf: {conf:.1f}%',\n",
    "        fontsize=9, color='red'\n",
    "    )\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Misclassified Examples (Best Model)', fontsize=14, y=1.02)\n",
    "plt.savefig('results/misclassified_examples.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: results/misclassified_examples.png')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Analyze misclassification patterns\n",
    "print('Misclassification Analysis:')\n",
    "print('=' * 55)\n",
    "print()\n",
    "print('Why does the model make these mistakes?')\n",
    "print('-' * 55)\n",
    "print('1. Shirt <-> T-shirt/top: Both are upper-body garments.')\n",
    "print('   In grayscale 28x28, the distinction between formal')\n",
    "print('   (buttoned) shirts and casual T-shirts is subtle.')\n",
    "print()\n",
    "print('2. Coat <-> Pullover: Both are long-sleeved outerwear.')\n",
    "print('   The difference in thickness/structure is hard to')\n",
    "print('   capture in low-resolution grayscale images.')\n",
    "print()\n",
    "print('3. Sneaker <-> Ankle boot: Both are closed footwear.')\n",
    "print('   The ankle height difference is the main distinguishing')\n",
    "print('   feature, which can be ambiguous at 28x28 resolution.')\n",
    "print()\n",
    "print('4. Sandal <-> Sneaker: Generally well-separated, but')\n",
    "print('   some sandal designs with straps can resemble sneakers.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Business Recommendations for StyleSort"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compute best model test accuracy for recommendations\n",
    "best_test_acc = test_accs[best_idx]\n",
    "t80_review = pct_review_at_t[t80_idx]\n",
    "\n",
    "print('=' * 65)\n",
    "print('BUSINESS RECOMMENDATIONS FOR STYLESORT')\n",
    "print('=' * 65)\n",
    "print()\n",
    "print('1. DEPLOYMENT STRATEGY')\n",
    "print('-' * 40)\n",
    "print(f'   - Deploy Classifier {best_idx+1} (test accuracy: {best_test_acc:.2f}%)')\n",
    "print('   - Use 80% confidence threshold for auto-classification')\n",
    "print(f'   - Expected ~{int(10000 * t80_review / 100)} of 10,000 daily items need human review')\n",
    "print()\n",
    "print('2. HIGH-PRIORITY IMPROVEMENTS')\n",
    "print('-' * 40)\n",
    "print('   - Shirt vs T-shirt: Add \"collar type\" and \"button\" tags')\n",
    "print('     to product photography guidelines')\n",
    "print('   - Coat vs Pullover: Require side-view photos showing')\n",
    "print('     garment thickness and structure')\n",
    "print()\n",
    "print('3. HUMAN REVIEW WORKFLOW')\n",
    "print('-' * 40)\n",
    "print('   - Auto-accept predictions with >80% confidence')\n",
    "print('   - Flag low-confidence items for human review')\n",
    "print('   - Prioritize review of Shirt/T-shirt and Coat/Pullover')\n",
    "print('     predictions (highest business cost if wrong)')\n",
    "print()\n",
    "print('4. COST REDUCTION')\n",
    "print('-' * 40)\n",
    "print('   - Focus on reducing high-cost errors (Shirt<->T-shirt,')\n",
    "print('     Coat<->Pullover) rather than all errors equally')\n",
    "print('   - Consider class-weighted loss function for fine-tuning')\n",
    "print()\n",
    "print('5. FUTURE IMPROVEMENTS')\n",
    "print('-' * 40)\n",
    "print('   - Use CNN architecture for better spatial feature extraction')\n",
    "print('   - Collect higher-resolution color product images')\n",
    "print('   - Implement data augmentation for underperforming classes')\n",
    "print('   - Consider transfer learning from pre-trained models')\n",
    "print('   - Increase training epochs with early stopping for')\n",
    "print('     better convergence without overfitting')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary\n",
    "\n",
    "### Key Results\n",
    "- **5 model configurations** were compared, varying depth (2\u20133 layers), activation (ReLU, ELU), hidden size (128\u2013512), batch normalization, and optimizer (Adam, AdamW)\n",
    "- **Best model (Classifier 1):** 3 hidden layers, ELU activation, 512 hidden units, batch normalization, Adam optimizer \u2014 achieved the highest test accuracy\n",
    "- All models exceeded the **85% accuracy target** required by StyleSort\n",
    "\n",
    "### What Worked Best\n",
    "- **Batch normalization** significantly improved training stability and final accuracy\n",
    "- **ELU activation** provided a slight edge over ReLU in deeper architectures\n",
    "- **Larger hidden sizes (512)** outperformed smaller ones (128, 256) when combined with batch normalization\n",
    "\n",
    "### Business Impact\n",
    "- The model can automatically categorize the majority of StyleSort's 10,000 daily listings\n",
    "- Confidence-based flagging enables efficient human-in-the-loop review\n",
    "- The most problematic category pairs (Shirt\u2194T-shirt, Coat\u2194Pullover) are identified for targeted improvement\n",
    "- Focused improvements on high-cost error pairs can further reduce the 32% return rate"
   ]
  }
 ]
}